## $ sudo install -m 644 file /etc/logstash/conf.d/
input {
  ## https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html#plugins-inputs-file-discover_interval
  ## default discover_interval: 15sec
  file {
    type => "sinkhole"
    path => "/home/vagrant/logs/sinkhole-*.csv"
    ## if debugging, force re-read
    start_position => "beginning"
    sincedb_path => "/dev/null"
  }
}

filter {
  if [type] == "sinkhole" {
    csv {
      ## FQDN can be domain or ip:port
      ## ex: "Wed Mar 02 12:56:58 2015",TV,111.236.223.39,NO,AA,www.google.com,WORKGROUP-ALPHA1,D31ZXN6,<NULL>,ab-cd-ef-b7-4d-40,
      columns => ["DATE (UTC)","CATEGORY","@clientip","Trash","ASSIGNTO","FQDN","WORKGROUP","NBNAME","NBUSER","client_mac","COMMENT" ]
      separator => ","
    }
    ## skip first line/column name
    if [CATEGORY] == "CATEGORY" {
      drop { }
    }
    if [message] =~ /^#/ {
      drop { }
    }
    ## split dstip:dport
    mutate { 
       split => ["FQDN", ":"]
    }
    mutate {
        remove_field => [ "Trash" ]
    }
    date { 
      locale => "en"
      match => [ "DATE (UTC)", "EEE MMM dd HH:mm:ss yyyy" ]
      timezone => "UTC"
    }
    geoip {
        source => "@clientip"
        target => "geoip"
        database => "/home/vagrant/GeoLiteCity.dat"
        add_field => [ "[geoip][coordinates]", "%{[geoip][longitude]}" ]
        add_field => [ "[geoip][coordinates]", "%{[geoip][latitude]}"  ]
    }
    mutate {
        convert => [ "[geoip][coordinates]", "float"]
    }
#    geoip { 
#    	source => "FQDN"
#    }
    ## https://www.elastic.co/guide/en/logstash/current/plugins-filters-cidr.html
  #  cidr {
  #      add_tag => [ "linklocal" ]
  #      address => [ "%{clientip}" ]
  #      network => [ "169.254.0.0/16", "fe80::/64" ]
  #  }
#    ## http://notes.asd.me.uk/2014/11/10/cleaning-up-mac-addresses-in-logstash/
#    sanitize_mac {
#        match => { "client_mac" => "client_mac_sanitized" }
#        fixcase => "lower"
#        separator => ":"
#    }
##  http://engineering.laterooms.com/enriching-logs-with-logstash/  (split url)
#    grok { 
#        match => [ "url_path", "^(?:\/(?<url_language>en|de|es|it|fr))?(?:\/p(?<url_partner>[0-9]+))?(?:\/pv(?<url_partner_value>[0-9a-zA-Z]+))?(?<url_page>.*)$" ] 
#    }

  }
}

output {  
    if [type] == "sinkhole" {
        #stdout { codec => rubydebug }
        elasticsearch { 
            action => "index"
            host => "localhost"
            index => "sinkhole-%{+YYYY.MM.dd}"
            workers => 1
        }
    }
}
